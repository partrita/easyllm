<h1 align="center">EasyLLM - </h1>

<div align="center">
	<a  href="https://pypi.org/project/easyllm" target="_blank">
		<img src="https://img.shields.io/pypi/v/easyllm.svg" />
	</a>
	<a  href="https://pypi.org/project/easyllm" target="_blank">
		<img src="https://img.shields.io/pypi/pyversions/easyllm" />
	</a>
	<a  href="https://github.com/philschmid/easyllm/blob/main/LICENSE" target="_blank">
		<img src="https://img.shields.io/pypi/l/easyllm" />
	</a>
	<a  href="https://github.com/philschmid/easyllm/actions?workflow=Unit Tests" target="_blank">
		<img src="https://github.com/philschmid/easyllm/workflows/Unit Tests/badge.svg" />
	</a>
  <a  href="https://github.com/pypa/hatch" target="_blank">
		<img src="https://img.shields.io/badge/%F0%9F%A5%9A-Hatch-4051b5.svg" />
	</a>
</div>


**EasyLLM**μ€ μ¤ν” μ†μ¤ λ° ν΄λ΅μ¦λ“ μ†μ¤ λ€κ·λ¨ μ–Έμ–΄ λ¨λΈ(LLM) μ‘μ—…μ„ μ„ν• **μ μ©ν• λ„κµ¬μ™€ λ°©λ²•**μ„ μ κ³µν•λ” μ¤ν” μ†μ¤ ν”„λ΅μ νΈμ…λ‹λ‹¤. μ¦‰μ‹ μ‹μ‘ν•κ±°λ‚ [λ¬Έμ„](https://philschmid.github.io/easyllm/)λ¥Ό ν™•μΈν•μ„Έμ”.

EasyLLMμ€ **OpenAIμ Completion APIμ™€ νΈν™λλ” ν΄λΌμ΄μ–ΈνΈ**λ¥Ό κµ¬ν„ν•©λ‹λ‹¤. μ¦‰, μ½”λ“ ν• μ¤„μ„ λ³€κ²½ν•μ—¬ `openai.ChatCompletion`, `openai.Completion`, `openai.Embedding`μ„ μλ¥Ό λ“¤μ–΄ `huggingface.ChatCompletion`, `huggingface.Completion` λλ” `huggingface.Embedding`μΌλ΅ μ‰½κ² λ°”κΏ€ μ μμµλ‹λ‹¤.

### μ§€μ›λλ” ν΄λΌμ΄μ–ΈνΈ

* `huggingface` - [HuggingFace](https://huggingface.co/) λ¨λΈ
  * `huggingface.ChatCompletion` - LLMκ³Ό μ±„ν…
  * `huggingface.Completion` - LLMμΌλ΅ ν…μ¤νΈ μ™„μ„±
  * `huggingface.Embedding` - LLMμΌλ΅ μ„λ² λ”© μƒμ„±
* `sagemaker` - Amazon SageMakerμ— λ°°ν¬λ μ¤ν” LLM
  * `sagemaker.ChatCompletion` - LLMκ³Ό μ±„ν…
  * `sagemaker.Completion` - LLMμΌλ΅ ν…μ¤νΈ μ™„μ„±
  * `sagemaker.Embedding` - LLMμΌλ΅ μ„λ² λ”© μƒμ„±
* `bedrock` - Amazon Bedrock LLM


μ‹μ‘ν•λ ¤λ©΄ [μμ ](./examples)λ¥Ό ν™•μΈν•μ„Έμ”.

## π€ μ‹μ‘ν•κΈ°

pipλ¥Ό ν†µν•΄ EasyLLMμ„ μ„¤μΉν•©λ‹λ‹¤:

```bash
pip install easyllm
```

κ·Έλ° λ‹¤μ ν΄λΌμ΄μ–ΈνΈλ¥Ό κ°€μ Έμ™€μ„ μ‚¬μ©ν•κΈ° μ‹μ‘ν•©λ‹λ‹¤:

```python

from easyllm.clients import huggingface

# llama2 ν”„λ΅¬ν”„νΈλ¥Ό λΉλ“ν•λ” ν—¬νΌ
huggingface.prompt_builder = "llama2"

response = huggingface.ChatCompletion.create(
    model="meta-llama/Llama-2-70b-chat-hf",
    messages=[
        {"role": "system", "content": "\nλ‹Ήμ‹ μ€ ν•΄μ μ²λΌ λ§ν•λ” λ„μ›€μ΄ λλ” μ΅°μμ…λ‹λ‹¤. μ•„λ¥΄!"},
        {"role": "user", "content": "νƒμ–‘μ΄λ€ λ¬΄μ—‡μΈκ°€?"},
    ],
    temperature=0.9,
    top_p=0.6,
    max_tokens=256,
)

print(response)
```
κ²°κ³Όλ” λ‹¤μκ³Ό κ°™μµλ‹λ‹¤

```bash
{
  "id": "hf-lVC2iTMkFJ",
  "object": "chat.completion",
  "created": 1690661144,
  "model": "meta-llama/Llama-2-70b-chat-hf",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": " μ•„λ¥΄λ¥΄, νƒμ–‘μ€ ν•λμ— λ–  μλ” μ»¤λ‹¤λ€ λ¶λ©μ–΄λ¦¬λΌλ„¤, μΉκµ¬! μ°λ¦¬ μ•„λ¦„λ‹¤μ΄ ν–‰μ„±μ— λΉ›κ³Ό λ”°μ¤ν•¨μ„ μ£Όλ” μ›μ²μ΄κ³ , κ°•λ ¥ν• νμ„ κ°€μ΅μ§€, μ•κ² λ‚? νƒμ–‘μ΄ μ—†λ‹¤λ©΄ μ°λ¦° μ–΄λ‘  μ†μ„ ν•­ν•΄ν•λ©° κΈΈμ„ μƒκ³  μ¶”μ„μ— λ–¨κ² λ  ν…λ‹, νƒμ–‘μ„ μ„ν•΄ νμ°¨κ² \"μ•Όλ¥΄!\"λ¥Ό μ™ΈμΉμκ³ , μΉκµ¬λ“¤! μ•„λ¥΄λ¥΄!"
      },
      "finish_reason": null
    }
  ],
  "usage": {
    "prompt_tokens": 111,
    "completion_tokens": 299,
    "total_tokens": 410
  }
}
```

λ‹¤λ¥Έ μμ λ¥Ό ν™•μΈν•μ„Έμ”:
* [μμ„Έν• ChatCompletion μμ ](notebooks/chat-completion-api.ipynb)
* [μ±„ν… μ”μ²­μ„ μ¤νΈλ¦¬λ°ν•λ” λ°©λ²• μμ ](notebooks/stream-chat-completions.ipynb)
* [ν…μ¤νΈ μ”μ²­μ„ μ¤νΈλ¦¬λ°ν•λ” λ°©λ²• μμ ](notebooks/stream-text-completions.ipynb)
* [μμ„Έν• Completion μμ ](notebooks/text-completion-api.ipynb)
* [μ„λ² λ”© μƒμ„±](notebooks/get-embeddings)

λ” μμ„Έν• μ‚¬μ©λ²•κ³Ό μμ λ” [λ¬Έμ„](https://philschmid.github.io/easyllm/)λ¥Ό μ°Έμ΅°ν•μ„Έμ”.

## π’π» OpenAIμ—μ„ HuggingFaceλ΅ λ§μ΄κ·Έλ μ΄μ…

OpenAIμ—μ„ HuggingFaceλ΅ λ§μ΄κ·Έλ μ΄μ…ν•λ” κ²ƒμ€ μ‰½μµλ‹λ‹¤. κ°€μ Έμ¤κΈ° λ¬Έκ³Ό μ‚¬μ©ν•λ ¤λ” ν΄λΌμ΄μ–ΈνΈλ¥Ό λ³€κ²½ν•κ³  μ„ νƒμ μΌλ΅ ν”„λ΅¬ν”„νΈ λΉλ”λ¥Ό λ³€κ²½ν•λ©΄ λ©λ‹λ‹¤.

```diff
- import openai
+ from easyllm.clients import huggingface
+ huggingface.prompt_builder = "llama2"


- response = openai.ChatCompletion.create(
+ response = huggingface.ChatCompletion.create(
-    model="gpt-3.5-turbo",
+    model="meta-llama/Llama-2-70b-chat-hf",
    messages=[
        {"role": "system", "content": "λ‹Ήμ‹ μ€ λ„μ›€μ΄ λλ” μ΅°μμ…λ‹λ‹¤."},
        {"role": "user", "content": "λ‘λ‘."},
    ],
)
```

ν΄λΌμ΄μ–ΈνΈλ¥Ό μ „ν™ν•  λ• ν•μ΄νΌνλΌλ―Έν„°κ°€ μ—¬μ „ν μ ν¨ν•μ§€ ν™•μΈν•μ„Έμ”. μλ¥Ό λ“¤μ–΄ GPT-3μ `temperature`λ” `Llama-2`μ `temperature`μ™€ λ‹¤λ¥Ό μ μμµλ‹λ‹¤.

## β‘οΈ μ£Όμ” κΈ°λ¥

### π¤ νΈν™λλ” ν΄λΌμ΄μ–ΈνΈ

- `openai.ChatCompletion`, `openai.Completion`, `openai.Embedding`μ OpenAI API ν•μ‹κ³Ό νΈν™λλ” ν΄λΌμ΄μ–ΈνΈ κµ¬ν„.
- μ½”λ“ ν• μ¤„μ„ λ³€κ²½ν•μ—¬ `openai.ChatCompletion`κ³Ό `huggingface.ChatCompletion`κ³Ό κ°™μ€ λ‹¤λ¥Έ LLM κ°„μ— μ‰½κ² μ „ν™ν•  μ μμµλ‹λ‹¤.
- μ™„μ„± μ¤νΈλ¦¬λ° μ§€μ›, [μ™„μ„± μ¤νΈλ¦¬λ° λ°©λ²•](./notebooks/stream-chat-completions.ipynb) μμ  ν™•μΈ.

### β™οΈ ν—¬νΌ λ¨λ“ β™οΈ

- `evol_instruct` (μ‘μ—… μ§„ν–‰ μ¤‘) - μ§„ν™” μ•κ³ λ¦¬μ¦μ„ μ‚¬μ©ν•μ—¬ LLMμ© μ§€μΉ¨μ„ λ§λ“­λ‹λ‹¤.

- `prompt_utils` - OpenAI λ©”μ‹μ§€μ™€ κ°™μ€ ν”„λ΅¬ν”„νΈ ν•μ‹μ„ Llama 2μ™€ κ°™μ€ μ¤ν” μ†μ¤ λ¨λΈμ© ν”„λ΅¬ν”„νΈλ΅ μ‰½κ² λ³€ν™ν•λ” ν—¬νΌ λ©”μ„λ“μ…λ‹λ‹¤.

## π™ κΈ°μ—¬

EasyLLMμ€ μ¤ν” μ†μ¤ ν”„λ΅μ νΈμ΄λ©° λ¨λ“  μΆ…λ¥μ κΈ°μ—¬λ¥Ό ν™μν•©λ‹λ‹¤.

μ΄ ν”„λ΅μ νΈλ” κ°λ°μ— [hatch](https://hatch.pypa.io/latest/)λ¥Ό μ‚¬μ©ν•©λ‹λ‹¤. μ‹μ‘ν•λ ¤λ©΄ λ¦¬ν¬μ§€ν† λ¦¬λ¥Ό ν¬ν¬ν•κ³  λ΅μ»¬ μ‹μ¤ν…μ— λ³µμ ν•μ„Έμ”.

0. [hatch](https://hatch.pypa.io/latest/install/)κ°€ μ„¤μΉλμ–΄ μλ”μ§€ ν™•μΈν•©λ‹λ‹¤ (pipxλ” μ‹μ¤ν… μ „μ²΄μ—μ„ μ‚¬μ©ν•  μ μλ„λ΅ ν•λ” λ° μ μ©ν•©λ‹λ‹¤).
1. ν”„λ΅μ νΈ λ””λ ‰ν„°λ¦¬μ—μ„ `hatch env create`λ¥Ό μ‹¤ν–‰ν•μ—¬ κ°λ°μ© κΈ°λ³Έ κ°€μƒ ν™κ²½μ„ λ§λ“­λ‹λ‹¤.
2. `hatch shell`λ΅ κ°€μƒ ν™κ²½μ„ ν™μ„±ν™”ν•©λ‹λ‹¤.
3. κ°λ°μ„ μ‹μ‘ν•μ„Έμ”! π¤©

## π“” μΈμ© λ° κ°μ‚¬

EasyLLMμ„ μ‚¬μ©ν•μ‹ λ‹¤λ©΄ μ†μ… λ―Έλ””μ–΄λ‚ μ΄λ©”μΌλ΅ μ €μ™€ κ³µμ ν•΄μ£Όμ„Έμ”. μ •λ§ λ“£κ³  μ‹¶μµλ‹λ‹¤!
λ‹¤μ BibTeXμ„ μ‚¬μ©ν•μ—¬ ν”„λ΅μ νΈλ¥Ό μΈμ©ν•  μλ„ μμµλ‹λ‹¤:

```bash
@software{Philipp_Schmid_EasyLLM_2023,
author = {Philipp Schmid},
license = {Apache-2.0},
month = juj,
title = {EasyLLM: Streamlined Tools for LLMs},
url = {https://github.com/philschmid/easyllm},
year = {2023}
}
```
